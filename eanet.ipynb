{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "authorship_tag": "ABX9TyMIgVyOt17FlH8lp6JiLPHI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paul2002/Advanced-Deep-Learning-with-Keras/blob/master/eanet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXifdbNTBCtw",
        "outputId": "57e53f4f-aed8-4906-a0ea-3d9509be181d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 522 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 552 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 604 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 634 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 686 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 716 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 747 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 768 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 798 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 829 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 849 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 880 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 931 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 942 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 962 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 993 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wEIknlTwBg0C",
        "outputId": "64c1dedb-eedc-46e2-9cb4-2b9fe334fe69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.8.0'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Title: Image classification with EANet (External Attention Transformer)\n",
        "Author: [ZhiYong Chang](https://github.com/czy00000)\n",
        "Date created: 2021/10/19\n",
        "Last modified: 2021/10/19\n",
        "Description: Image classification with a Transformer that leverages external attention.\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "## Introduction\n",
        "\n",
        "This example implements the [EANet](https://arxiv.org/abs/2105.02358)\n",
        "model for image classification, and demonstrates it on the CIFAR-100 dataset.\n",
        "EANet introduces a novel attention mechanism\n",
        "named ***external attention***, based on two external, small, learnable, and\n",
        "shared memories, which can be implemented easily by simply using two cascaded\n",
        "linear layers and two normalization layers. It conveniently replaces self-attention\n",
        "as used in existing architectures. External attention has linear complexity, as it only\n",
        "implicitly considers the correlations between all samples.\n",
        "\n",
        "This example requires TensorFlow 2.5 or higher, as well as\n",
        "[TensorFlow Addons](https://www.tensorflow.org/addons/overview) package,\n",
        "which can be installed using the following command:\n",
        "\n",
        "```python\n",
        "pip install -U tensorflow-addons\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "## Setup\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## Prepare the data\n",
        "\"\"\"\n",
        "\n",
        "num_classes = 100\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
        "\n",
        "\"\"\"\n",
        "## Configure the hyperparameters\n",
        "\"\"\"\n",
        "\n",
        "weight_decay = 0.0001\n",
        "learning_rate = 0.001\n",
        "label_smoothing = 0.1\n",
        "validation_split = 0.2\n",
        "batch_size = 128\n",
        "num_epochs = 50\n",
        "patch_size = 2  # Size of the patches to be extracted from the input images.\n",
        "num_patches = (input_shape[0] // patch_size) ** 2  # Number of patch\n",
        "embedding_dim = 64  # Number of hidden units.\n",
        "mlp_dim = 64\n",
        "dim_coefficient = 4\n",
        "num_heads = 4\n",
        "attention_dropout = 0.2\n",
        "projection_dropout = 0.2\n",
        "num_transformer_blocks = 8  # Number of repetitions of the transformer layer\n",
        "\n",
        "print(f\"Patch size: {patch_size} X {patch_size} = {patch_size ** 2} \")\n",
        "print(f\"Patches per image: {num_patches}\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## Use data augmentation\n",
        "\"\"\"\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.1),\n",
        "        layers.RandomContrast(factor=0.1),\n",
        "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(x_train)\n",
        "\n",
        "\"\"\"\n",
        "## Implement the patch extraction and encoding layer\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class PatchExtract(layers.Layer):\n",
        "    def __init__(self, patch_size, **kwargs):\n",
        "        super(PatchExtract, self).__init__(**kwargs)\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=(1, self.patch_size, self.patch_size, 1),\n",
        "            strides=(1, self.patch_size, self.patch_size, 1),\n",
        "            rates=(1, 1, 1, 1),\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dim = patches.shape[-1]\n",
        "        patch_num = patches.shape[1]\n",
        "        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n",
        "\n",
        "\n",
        "class PatchEmbedding(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        super(PatchEmbedding, self).__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.proj = layers.Dense(embed_dim)\n",
        "        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, patch):\n",
        "        pos = tf.range(start=0, limit=self.num_patch, delta=1)\n",
        "        return self.proj(patch) + self.pos_embed(pos)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## Implement the external attention block\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def external_attention(\n",
        "    x, dim, num_heads, dim_coefficient=4, attention_dropout=0, projection_dropout=0\n",
        "):\n",
        "    _, num_patch, channel = x.shape\n",
        "    assert dim % num_heads == 0\n",
        "    num_heads = num_heads * dim_coefficient\n",
        "\n",
        "    x = layers.Dense(dim * dim_coefficient)(x)\n",
        "    # create tensor [batch_size, num_patches, num_heads, dim*dim_coefficient//num_heads]\n",
        "    x = tf.reshape(\n",
        "        x, shape=(-1, num_patch, num_heads, dim * dim_coefficient // num_heads)\n",
        "    )\n",
        "    x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    # a linear layer M_k\n",
        "    attn = layers.Dense(dim // dim_coefficient)(x)\n",
        "    # normalize attention map\n",
        "    attn = layers.Softmax(axis=2)(attn)\n",
        "    # dobule-normalization\n",
        "    attn = attn / (1e-9 + tf.reduce_sum(attn, axis=-1, keepdims=True))\n",
        "    attn = layers.Dropout(attention_dropout)(attn)\n",
        "    # a linear layer M_v\n",
        "    x = layers.Dense(dim * dim_coefficient // num_heads)(attn)\n",
        "    x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    x = tf.reshape(x, [-1, num_patch, dim * dim_coefficient])\n",
        "    # a linear layer to project original dim\n",
        "    x = layers.Dense(dim)(x)\n",
        "    x = layers.Dropout(projection_dropout)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## Implement the MLP block\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def mlp(x, embedding_dim, mlp_dim, drop_rate=0.2):\n",
        "    x = layers.Dense(mlp_dim, activation=tf.nn.gelu)(x)\n",
        "    x = layers.Dropout(drop_rate)(x)\n",
        "    x = layers.Dense(embedding_dim)(x)\n",
        "    x = layers.Dropout(drop_rate)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## Implement the Transformer block\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def transformer_encoder(\n",
        "    x,\n",
        "    embedding_dim,\n",
        "    mlp_dim,\n",
        "    num_heads,\n",
        "    dim_coefficient,\n",
        "    attention_dropout,\n",
        "    projection_dropout,\n",
        "    attention_type=\"external_attention\",\n",
        "):\n",
        "    residual_1 = x\n",
        "    x = layers.LayerNormalization(epsilon=1e-5)(x)\n",
        "    if attention_type == \"external_attention\":\n",
        "        x = external_attention(\n",
        "            x,\n",
        "            embedding_dim,\n",
        "            num_heads,\n",
        "            dim_coefficient,\n",
        "            attention_dropout,\n",
        "            projection_dropout,\n",
        "        )\n",
        "    elif attention_type == \"self_attention\":\n",
        "        x = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embedding_dim, dropout=attention_dropout\n",
        "        )(x, x)\n",
        "    x = layers.add([x, residual_1])\n",
        "    residual_2 = x\n",
        "    x = layers.LayerNormalization(epsilon=1e-5)(x)\n",
        "    x = mlp(x, embedding_dim, mlp_dim)\n",
        "    x = layers.add([x, residual_2])\n",
        "    return x\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## Implement the EANet model\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "The EANet model leverages external attention.\n",
        "The computational complexity of traditional self attention is `O(d * N ** 2)`,\n",
        "where `d` is the embedding size, and `N` is the number of patch.\n",
        "the authors find that most pixels are closely related to just a few other\n",
        "pixels, and an `N`-to-`N` attention matrix may be redundant.\n",
        "So, they propose as an alternative an external\n",
        "attention module where the computational complexity of external attention is `O(d * S * N)`.\n",
        "As `d` and `S` are hyper-parameters,\n",
        "the proposed algorithm is linear in the number of pixels. In fact, this is equivalent\n",
        "to a drop patch operation, because a lot of information contained in a patch\n",
        "in an image is redundant and unimportant.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def get_model(attention_type=\"external_attention\"):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Image augment\n",
        "    x = data_augmentation(inputs)\n",
        "    # Extract patches.\n",
        "    x = PatchExtract(patch_size)(x)\n",
        "    # Create patch embedding.\n",
        "    x = PatchEmbedding(num_patches, embedding_dim)(x)\n",
        "    # Create Transformer block.\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(\n",
        "            x,\n",
        "            embedding_dim,\n",
        "            mlp_dim,\n",
        "            num_heads,\n",
        "            dim_coefficient,\n",
        "            attention_dropout,\n",
        "            projection_dropout,\n",
        "            attention_type,\n",
        "        )\n",
        "\n",
        "    x = layers.GlobalAvgPool1D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## Train on CIFAR-100\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "model = get_model(attention_type=\"external_attention\")\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing),\n",
        "    optimizer=tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    ),\n",
        "    metrics=[\n",
        "        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
        "        keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "    ],\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=num_epochs,\n",
        "    validation_split=validation_split,\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "### Let's visualize the training progress of the model.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train and Validation Losses Over Epochs\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "### Let's display the final results of the test on CIFAR-100.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "loss, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test loss: {round(loss, 2)}\")\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "\"\"\"\n",
        "EANet just replaces self attention in Vit with external attention.\n",
        "The traditional Vit achieved a ~73% test top-5 accuracy and ~41 top-1 accuracy after\n",
        "training 50 epochs, but with 0.6M parameters. Under the same experimental environment\n",
        "and the same hyperparameters, The EANet model we just trained has just 0.3M parameters,\n",
        "and it gets us to ~73% test top-5 accuracy and ~43% top-1 accuracy. This fully demonstrates the\n",
        "effectiveness of external attention.\n",
        "\n",
        "We only show the training\n",
        "process of EANet, you can train Vit under the same experimental conditions and observe\n",
        "the test results.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WprgGvSYBQcp",
        "outputId": "86e64876-d0ab-4362-92fb-d3fe15469efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n",
            "169017344/169001437 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 100)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 100)\n",
            "Patch size: 2 X 2 = 4 \n",
            "Patches per image: 256\n",
            "Epoch 1/50\n",
            "313/313 [==============================] - 212s 620ms/step - loss: 4.1990 - accuracy: 0.0738 - top-5-accuracy: 0.2413 - val_loss: 3.9764 - val_accuracy: 0.1135 - val_top-5-accuracy: 0.3293\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - 192s 614ms/step - loss: 3.8132 - accuracy: 0.1421 - top-5-accuracy: 0.3823 - val_loss: 3.7668 - val_accuracy: 0.1630 - val_top-5-accuracy: 0.4213\n",
            "Epoch 3/50\n",
            "313/313 [==============================] - 192s 612ms/step - loss: 3.5579 - accuracy: 0.1979 - top-5-accuracy: 0.4794 - val_loss: 3.4882 - val_accuracy: 0.2293 - val_top-5-accuracy: 0.5182\n",
            "Epoch 4/50\n",
            "313/313 [==============================] - 192s 612ms/step - loss: 3.4037 - accuracy: 0.2372 - top-5-accuracy: 0.5318 - val_loss: 3.4152 - val_accuracy: 0.2349 - val_top-5-accuracy: 0.5450\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - 192s 613ms/step - loss: 3.3019 - accuracy: 0.2614 - top-5-accuracy: 0.5626 - val_loss: 3.3807 - val_accuracy: 0.2537 - val_top-5-accuracy: 0.5543\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - 192s 613ms/step - loss: 3.2113 - accuracy: 0.2845 - top-5-accuracy: 0.5914 - val_loss: 3.2214 - val_accuracy: 0.2885 - val_top-5-accuracy: 0.6052\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - 191s 612ms/step - loss: 3.1550 - accuracy: 0.2975 - top-5-accuracy: 0.6058 - val_loss: 3.1962 - val_accuracy: 0.2952 - val_top-5-accuracy: 0.6122\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - 191s 612ms/step - loss: 3.0994 - accuracy: 0.3099 - top-5-accuracy: 0.6235 - val_loss: 3.1857 - val_accuracy: 0.2998 - val_top-5-accuracy: 0.6155\n",
            "Epoch 9/50\n",
            "313/313 [==============================] - 191s 612ms/step - loss: 3.0458 - accuracy: 0.3232 - top-5-accuracy: 0.6390 - val_loss: 3.1127 - val_accuracy: 0.3154 - val_top-5-accuracy: 0.6327\n",
            "Epoch 10/50\n",
            "313/313 [==============================] - 192s 613ms/step - loss: 3.0027 - accuracy: 0.3341 - top-5-accuracy: 0.6514 - val_loss: 3.0519 - val_accuracy: 0.3308 - val_top-5-accuracy: 0.6468\n",
            "Epoch 11/50\n",
            "313/313 [==============================] - 192s 612ms/step - loss: 2.9645 - accuracy: 0.3469 - top-5-accuracy: 0.6643 - val_loss: 3.0889 - val_accuracy: 0.3270 - val_top-5-accuracy: 0.6444\n",
            "Epoch 12/50\n",
            "313/313 [==============================] - 191s 611ms/step - loss: 2.9309 - accuracy: 0.3532 - top-5-accuracy: 0.6721 - val_loss: 3.1026 - val_accuracy: 0.3215 - val_top-5-accuracy: 0.6445\n",
            "Epoch 13/50\n",
            "313/313 [==============================] - 191s 611ms/step - loss: 2.8991 - accuracy: 0.3612 - top-5-accuracy: 0.6797 - val_loss: 3.0871 - val_accuracy: 0.3356 - val_top-5-accuracy: 0.6499\n",
            "Epoch 14/50\n",
            "313/313 [==============================] - 191s 611ms/step - loss: 2.8751 - accuracy: 0.3697 - top-5-accuracy: 0.6893 - val_loss: 2.9944 - val_accuracy: 0.3597 - val_top-5-accuracy: 0.6753\n",
            "Epoch 15/50\n",
            "313/313 [==============================] - 191s 611ms/step - loss: 2.8468 - accuracy: 0.3758 - top-5-accuracy: 0.6953 - val_loss: 3.0578 - val_accuracy: 0.3403 - val_top-5-accuracy: 0.6628\n",
            "Epoch 16/50\n",
            "313/313 [==============================] - 191s 611ms/step - loss: 2.8165 - accuracy: 0.3836 - top-5-accuracy: 0.7048 - val_loss: 2.9789 - val_accuracy: 0.3612 - val_top-5-accuracy: 0.6799\n",
            "Epoch 17/50\n",
            "313/313 [==============================] - 191s 611ms/step - loss: 2.7976 - accuracy: 0.3906 - top-5-accuracy: 0.7098 - val_loss: 3.0220 - val_accuracy: 0.3514 - val_top-5-accuracy: 0.6714\n",
            "Epoch 18/50\n",
            "313/313 [==============================] - 191s 611ms/step - loss: 2.7784 - accuracy: 0.3930 - top-5-accuracy: 0.7117 - val_loss: 2.9168 - val_accuracy: 0.3750 - val_top-5-accuracy: 0.6938\n",
            "Epoch 19/50\n",
            "313/313 [==============================] - 191s 611ms/step - loss: 2.7662 - accuracy: 0.3985 - top-5-accuracy: 0.7146 - val_loss: 2.9141 - val_accuracy: 0.3788 - val_top-5-accuracy: 0.6973\n",
            "Epoch 20/50\n",
            "313/313 [==============================] - 191s 610ms/step - loss: 2.7440 - accuracy: 0.4031 - top-5-accuracy: 0.7225 - val_loss: 2.8867 - val_accuracy: 0.3855 - val_top-5-accuracy: 0.6981\n",
            "Epoch 21/50\n",
            "313/313 [==============================] - 191s 611ms/step - loss: 2.7242 - accuracy: 0.4080 - top-5-accuracy: 0.7283 - val_loss: 2.9367 - val_accuracy: 0.3723 - val_top-5-accuracy: 0.6938\n",
            "Epoch 22/50\n",
            "313/313 [==============================] - 191s 611ms/step - loss: 2.7116 - accuracy: 0.4132 - top-5-accuracy: 0.7300 - val_loss: 2.8102 - val_accuracy: 0.4027 - val_top-5-accuracy: 0.7181\n",
            "Epoch 23/50\n",
            "313/313 [==============================] - 191s 609ms/step - loss: 2.6920 - accuracy: 0.4150 - top-5-accuracy: 0.7346 - val_loss: 2.8376 - val_accuracy: 0.4013 - val_top-5-accuracy: 0.7198\n",
            "Epoch 24/50\n",
            "313/313 [==============================] - 191s 609ms/step - loss: 2.6831 - accuracy: 0.4196 - top-5-accuracy: 0.7376 - val_loss: 2.9696 - val_accuracy: 0.3733 - val_top-5-accuracy: 0.6988\n",
            "Epoch 25/50\n",
            "313/313 [==============================] - 191s 609ms/step - loss: 2.6727 - accuracy: 0.4191 - top-5-accuracy: 0.7396 - val_loss: 2.8404 - val_accuracy: 0.3991 - val_top-5-accuracy: 0.7200\n",
            "Epoch 26/50\n",
            "313/313 [==============================] - 190s 609ms/step - loss: 2.6630 - accuracy: 0.4234 - top-5-accuracy: 0.7423 - val_loss: 2.9262 - val_accuracy: 0.3813 - val_top-5-accuracy: 0.7008\n",
            "Epoch 27/50\n",
            "313/313 [==============================] - 190s 608ms/step - loss: 2.6435 - accuracy: 0.4297 - top-5-accuracy: 0.7513 - val_loss: 2.8746 - val_accuracy: 0.3953 - val_top-5-accuracy: 0.7161\n",
            "Epoch 28/50\n",
            "313/313 [==============================] - 190s 607ms/step - loss: 2.6245 - accuracy: 0.4362 - top-5-accuracy: 0.7538 - val_loss: 2.8142 - val_accuracy: 0.4111 - val_top-5-accuracy: 0.7292\n",
            "Epoch 29/50\n",
            "313/313 [==============================] - 190s 608ms/step - loss: 2.6161 - accuracy: 0.4372 - top-5-accuracy: 0.7538 - val_loss: 2.8863 - val_accuracy: 0.4000 - val_top-5-accuracy: 0.7175\n",
            "Epoch 30/50\n",
            "313/313 [==============================] - 190s 607ms/step - loss: 2.6063 - accuracy: 0.4424 - top-5-accuracy: 0.7561 - val_loss: 2.8105 - val_accuracy: 0.4030 - val_top-5-accuracy: 0.7308\n",
            "Epoch 31/50\n",
            "313/313 [==============================] - 190s 608ms/step - loss: 2.5954 - accuracy: 0.4460 - top-5-accuracy: 0.7591 - val_loss: 2.9005 - val_accuracy: 0.3954 - val_top-5-accuracy: 0.7172\n",
            "Epoch 32/50\n",
            "313/313 [==============================] - 190s 608ms/step - loss: 2.5857 - accuracy: 0.4429 - top-5-accuracy: 0.7641 - val_loss: 2.8725 - val_accuracy: 0.3959 - val_top-5-accuracy: 0.7224\n",
            "Epoch 33/50\n",
            "313/313 [==============================] - 190s 608ms/step - loss: 2.5768 - accuracy: 0.4491 - top-5-accuracy: 0.7644 - val_loss: 2.8413 - val_accuracy: 0.4056 - val_top-5-accuracy: 0.7254\n",
            "Epoch 34/50\n",
            "313/313 [==============================] - 190s 608ms/step - loss: 2.5662 - accuracy: 0.4484 - top-5-accuracy: 0.7685 - val_loss: 2.8594 - val_accuracy: 0.4022 - val_top-5-accuracy: 0.7251\n",
            "Epoch 35/50\n",
            "313/313 [==============================] - 190s 607ms/step - loss: 2.5663 - accuracy: 0.4521 - top-5-accuracy: 0.7679 - val_loss: 2.8721 - val_accuracy: 0.3998 - val_top-5-accuracy: 0.7230\n",
            "Epoch 36/50\n",
            "313/313 [==============================] - 190s 608ms/step - loss: 2.5485 - accuracy: 0.4570 - top-5-accuracy: 0.7713 - val_loss: 2.7716 - val_accuracy: 0.4150 - val_top-5-accuracy: 0.7413\n",
            "Epoch 37/50\n",
            "313/313 [==============================] - 191s 610ms/step - loss: 2.5433 - accuracy: 0.4571 - top-5-accuracy: 0.7754 - val_loss: 2.8754 - val_accuracy: 0.4038 - val_top-5-accuracy: 0.7226\n",
            "Epoch 38/50\n",
            "313/313 [==============================] - 191s 612ms/step - loss: 2.5348 - accuracy: 0.4636 - top-5-accuracy: 0.7753 - val_loss: 2.8764 - val_accuracy: 0.4015 - val_top-5-accuracy: 0.7239\n",
            "Epoch 39/50\n",
            "313/313 [==============================] - 191s 611ms/step - loss: 2.5307 - accuracy: 0.4595 - top-5-accuracy: 0.7760 - val_loss: 2.8801 - val_accuracy: 0.4050 - val_top-5-accuracy: 0.7250\n",
            "Epoch 40/50\n",
            "313/313 [==============================] - 191s 610ms/step - loss: 2.5260 - accuracy: 0.4640 - top-5-accuracy: 0.7774 - val_loss: 2.8190 - val_accuracy: 0.4137 - val_top-5-accuracy: 0.7352\n",
            "Epoch 41/50\n",
            "313/313 [==============================] - 191s 611ms/step - loss: 2.5090 - accuracy: 0.4703 - top-5-accuracy: 0.7785 - val_loss: 2.8974 - val_accuracy: 0.4048 - val_top-5-accuracy: 0.7208\n",
            "Epoch 42/50\n",
            "313/313 [==============================] - 191s 611ms/step - loss: 2.5057 - accuracy: 0.4685 - top-5-accuracy: 0.7819 - val_loss: 2.7489 - val_accuracy: 0.4281 - val_top-5-accuracy: 0.7488\n",
            "Epoch 43/50\n",
            "313/313 [==============================] - 191s 610ms/step - loss: 2.4966 - accuracy: 0.4710 - top-5-accuracy: 0.7832 - val_loss: 2.8593 - val_accuracy: 0.4076 - val_top-5-accuracy: 0.7268\n",
            "Epoch 44/50\n",
            "313/313 [==============================] - 190s 608ms/step - loss: 2.4909 - accuracy: 0.4736 - top-5-accuracy: 0.7853 - val_loss: 2.8070 - val_accuracy: 0.4214 - val_top-5-accuracy: 0.7368\n",
            "Epoch 45/50\n",
            "313/313 [==============================] - 190s 608ms/step - loss: 2.4853 - accuracy: 0.4724 - top-5-accuracy: 0.7848 - val_loss: 2.7940 - val_accuracy: 0.4222 - val_top-5-accuracy: 0.7429\n",
            "Epoch 46/50\n",
            "313/313 [==============================] - 191s 611ms/step - loss: 2.4853 - accuracy: 0.4778 - top-5-accuracy: 0.7843 - val_loss: 2.8654 - val_accuracy: 0.4099 - val_top-5-accuracy: 0.7285\n",
            "Epoch 47/50\n",
            "313/313 [==============================] - 191s 611ms/step - loss: 2.4706 - accuracy: 0.4825 - top-5-accuracy: 0.7916 - val_loss: 2.8033 - val_accuracy: 0.4275 - val_top-5-accuracy: 0.7408\n",
            "Epoch 48/50\n",
            "313/313 [==============================] - 192s 613ms/step - loss: 2.4719 - accuracy: 0.4770 - top-5-accuracy: 0.7899 - val_loss: 2.8286 - val_accuracy: 0.4151 - val_top-5-accuracy: 0.7359\n",
            "Epoch 49/50\n",
            "313/313 [==============================] - 192s 613ms/step - loss: 2.4750 - accuracy: 0.4765 - top-5-accuracy: 0.7881 - val_loss: 2.8245 - val_accuracy: 0.4162 - val_top-5-accuracy: 0.7378\n",
            "Epoch 50/50\n",
            "313/313 [==============================] - 192s 613ms/step - loss: 2.4594 - accuracy: 0.4793 - top-5-accuracy: 0.7934 - val_loss: 2.7835 - val_accuracy: 0.4283 - val_top-5-accuracy: 0.7446\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 28s 89ms/step - loss: 2.7354 - accuracy: 0.4373 - top-5-accuracy: 0.7483\n",
            "Test loss: 2.74\n",
            "Test accuracy: 43.73%\n",
            "Test top 5 accuracy: 74.83%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nEANet just replaces self attention in Vit with external attention.\\nThe traditional Vit achieved a ~73% test top-5 accuracy and ~41 top-1 accuracy after\\ntraining 50 epochs, but with 0.6M parameters. Under the same experimental environment\\nand the same hyperparameters, The EANet model we just trained has just 0.3M parameters,\\nand it gets us to ~73% test top-5 accuracy and ~43% top-1 accuracy. This fully demonstrates the\\neffectiveness of external attention.\\n\\nWe only show the training\\nprocess of EANet, you can train Vit under the same experimental conditions and observe\\nthe test results.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}